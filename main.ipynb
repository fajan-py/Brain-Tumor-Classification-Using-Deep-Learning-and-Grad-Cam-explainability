{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Import libraries for model training\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torchvision import  transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import efficientnet_b0\n",
    "from train import train_one_epoch\n",
    "from evaluate import evaluate_model\n",
    "\n",
    "# Import PIL for image processing\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used this Grad-CAM library to visualize the area that the model detected as meningioma tumor\n",
    "# As the first step, I cloned the library from the github repository\n",
    "!git clone https://github.com/jacobgil/pytorch-grad-cam.git\n",
    "%cd pytorch-grad-cam\n",
    "!pip install ttach\n",
    "\n",
    "#Importing necessary libraries for Gradcam(These libraries need to clone a github library that I mentioned in readme file)\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I defined paths for training and testing data and used glob to get all the files in the directories\n",
    "train_dir = \"/kaggle/input/brain-tumor-mri-dataset/Training\"\n",
    "test_dir = \"/kaggle/input/brain-tumor-mri-dataset/Testing\"\n",
    "train_files = glob.glob(train_dir + \"/*/*\")  \n",
    "test_files = glob.glob(test_dir + \"/*/*\")\n",
    "#here I wanted to make sure that I have same number of files in both training and testing directories\n",
    "print(f\"Number of training files: {len(train_files)}\")\n",
    "print(f\"Number of testing files: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I extracted the labels using the paths of the files then I used label encoder to encode the labels of the classes\n",
    "train_labels =[]\n",
    "for paths in train_files:\n",
    "    label = paths.split('/')[5]\n",
    "    train_labels.append(label)\n",
    "    \n",
    "test_labels =[]\n",
    "for paths in test_files:\n",
    "    label = paths.split('/')[5]\n",
    "    test_labels.append(label)\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "test_labels = label_encoder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I defined a class for the dataset and used torchvision.transforms to resize the images to 224x224 and normalize them using ImageNet mean and std\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, files_dir_list, labels, transforms=None):\n",
    "        super().__init__()\n",
    "        self.files_dir_list = files_dir_list\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.files_dir_list[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        label = self.labels[index]\n",
    "        return image,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I made datasets and dataloaders for training and testing data\n",
    "train_dataset = BrainTumorDataset(train_files, train_labels, my_transforms)\n",
    "test_dataset = BrainTumorDataset(test_files, test_labels, my_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used efficientnet_b0 model and changed the last layer to have 4 output features and used CrossEntropyLoss as loss function and Adam as optimizer\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = efficientnet_b0(pretrained=False)\n",
    "model.classifier[1] = nn.Linear(in_features=1280, out_features=4, bias=True).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model for 20 epochs and saving the model's state_dict right after training\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_one_epoch(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        None,\n",
    "        epoch,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "torch.save(model.state_dict(), 'efficientnet_b0_on_nickparvar_20epochs_braintumor_dataset.pth')\n",
    "print(\"Model state_dict saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then, I evaluated the model on the test data to get the accuracy and f1 score\n",
    "evaluate_model(model, test_dataloader, device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, I uploaded a photo and used the model to predict the class of the photo, as it is obvious from the name of the file, it was a random meningiom tumor photo\n",
    "# and the model predicted the class correctly\n",
    "im_path = \"/kaggle/input/mening/c72f1a6cc058e783ec8e518fbb0061_big_gallery.jpg\"\n",
    "image = Image.open(im_path).convert('RGB')\n",
    "plt.imshow(image, cmap='gray')\n",
    "image = my_transforms(image)\n",
    "\n",
    "image = image.to(device)\n",
    "model = model.to(device)  \n",
    "output = model(image.unsqueeze(dim=0)).argmax()\n",
    "final_output = output.cpu().numpy()\n",
    "\n",
    "print(f'''All classes include:\n",
    "    {label_encoder.classes_}''')\n",
    "model_prediction = label_encoder.inverse_transform([final_output])\n",
    "print(f'''Model's prediction for uploaded photo is{model_prediction}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Grad-Cam implementation, I chosed 3rd layer of the model as the target layer\n",
    "target_layers = [model.features[7][0]]\n",
    "image_path = \"/kaggle/input/mening/c72f1a6cc058e783ec8e518fbb0061_big_gallery.jpg\"\n",
    "input_image = Image.open(image_path).convert('RGB')\n",
    "input_image = my_transforms(input_image).unsqueeze(0).to(device)\n",
    "\n",
    "#meningioma is the target class since my photo is a meningioma tumor and I want to check if my model can detect the area\n",
    "target_class = label_encoder.transform([\"meningioma\"])[0]  \n",
    "targets = [ClassifierOutputTarget(target_class)]\n",
    "\n",
    "\n",
    "with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "    \n",
    "    grayscale_cam = cam(input_tensor=input_image, targets=targets)\n",
    "    grayscale_cam = grayscale_cam[0, :]  \n",
    "    rgb_image = input_image[0].permute(1, 2, 0).cpu().numpy()  \n",
    "    rgb_image = (rgb_image - rgb_image.min()) / (rgb_image.max() - rgb_image.min())  \n",
    "\n",
    "    #The final photo consists of the heatmap of the area that the model detected as meningioma tumor as well as the original photo\n",
    "    final_visualization = show_cam_on_image(rgb_image, grayscale_cam, use_rgb=True)\n",
    "\n",
    "\n",
    "plt.imshow(final_visualization)\n",
    "plt.title(f\"Grad-CAM Heatmap for Predicted Class: Meningioma\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
